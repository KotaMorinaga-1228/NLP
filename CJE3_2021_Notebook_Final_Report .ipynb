{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBmgoRqWciYc"
      },
      "source": [
        "**学生用**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdymDxxcciYh"
      },
      "source": [
        "# 2021年度知識情報演習III（後半）最終レポート\n",
        "本ノートブックは、知識情報演習III（後半）のレポート提出用です。\n",
        "\n",
        "- 課題1〜2は全員向けの課題です（未完成でも採点します）\n",
        "- 課題3は腕に覚えがある上級者向けの**任意課題**（加点対象）です\n",
        "- 課題4は全員向けのアンケート（任意）です\n",
        "- **↓の学籍番号と氏名が未記入のレポートは採点対象になりませんので、必ず記入してください。**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_eZAoChMtdeD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aTCh5grciYi"
      },
      "source": [
        "---\n",
        "## 学生情報\n",
        "\n",
        "- 学籍番号：202011470\n",
        "- 氏名：盛永浩太\n",
        "\n",
        "## 宣誓\n",
        "\n",
        "私は本レポートの提出にあたり、以下の内容を誓います。\n",
        "\n",
        "- 本レポートは上記氏名の本人自身が作成した。\n",
        "- 他人のレポートやプログラムを写すなどを含む一切の不正行為をしていない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAHa3GxmciYi"
      },
      "source": [
        "---\n",
        "## 提出方法\n",
        "\n",
        "Manaba\n",
        "  - レポート → 後半：最終レポートノートブック → ノートブックをアップロード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmGaL--kciYj"
      },
      "source": [
        "---\n",
        "### 課題1-1：索引付け処理のプログラムを書きなさい\n",
        "\n",
        "- ノートブック5で作成したプログラムを清書したものです。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSp6O0GGciYj"
      },
      "outputs": [],
      "source": [
        "\n",
        "#---------------------------------------------\n",
        "# 1. 初期設定\n",
        "#---------------------------------------------\n",
        "\n",
        "### A. ライブラリの読み込み\n",
        "import os\n",
        "import math\n",
        "import re\n",
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "# 分かち書きクラスの初期化\n",
        "t = Tokenizer()\n",
        "\n",
        "### B. フォルダやファイル名の設定\n",
        "\n",
        "# データフォルダの設定\n",
        "DATA =  CJE3 + \"/data\"\n",
        "# 索引ファイルの指定\n",
        "INDEX = CJE3 + \"/index\"\n",
        "index_file = INDEX + \"/index3.txt\"\n",
        "\n",
        "### C. 各種辞書オブジェクトの初期化\n",
        "\n",
        "# 索引語用辞書オブジェクトの初期化\n",
        "dict = {}\n",
        "# 不要語辞書の初期化\n",
        "stopwords = {}\n",
        "# ファイル名保存用辞書オブジェクト\n",
        "docs = {}\n",
        "# df用辞書オブジェクトの初期化\n",
        "df = {}\n",
        "# idf値用辞書オブジェクト\n",
        "idf = {}\n",
        "\n",
        "#---------------------------------------------\n",
        "# 2. 不用語削除ルールの定義\n",
        "#---------------------------------------------\n",
        "\n",
        "### A. 正規表現\n",
        "pattern = re.compile(r\"^[　-ー]$\")\n",
        "\n",
        "### B. 不要語リスト\n",
        "stopwords['という'] = 1\n",
        "stopwords['にて'] = 1\n",
        "\n",
        "#---------------------------------------------\n",
        "# 3. 文書ファイルの処理\n",
        "#---------------------------------------------\n",
        "\n",
        "# DATAフォルダに含まれるファイルを一つずつ処理\n",
        "for filename in os.listdir(DATA):\n",
        "    # ファイルを読み込みモードで開く\n",
        "  f = open(DATA + '/' + filename, 'r')\n",
        "    # ファイルを1行ずつ処理\n",
        "  for line in f:\n",
        "        ### A. 分かち書き\n",
        "    tokens = t.tokenize(line)\n",
        "        # 分かち書きされた語オブジェクトの処理\n",
        "    for token in tokens:\n",
        "      key = token.surface\n",
        "            ### B. 不用語処理\n",
        "            # 正規表現\n",
        "      if pattern.match(key):\n",
        "        continue\n",
        "            # 不用語リスト\n",
        "      if key in stopwords:\n",
        "        continue\n",
        "            ### C. 索引語の追加\n",
        "      if key in dict:\n",
        "        if filename in dict[key]:\n",
        "          dict[key][filename] += 1\n",
        "        else:\n",
        "          dict[key][filename] = 1\n",
        "\n",
        "      else:\n",
        "        dict[key] = {}\n",
        "        dict[key][filename] = 1\n",
        "\n",
        "#---------------------------------------------\n",
        "# 4. 索引語の重み付け\n",
        "#---------------------------------------------\n",
        "\n",
        "### A. 総文書数の算出\n",
        "\n",
        "# 索引語を一つずつ処理\n",
        "for word in dict:\n",
        "    # 文書を一つずつ処理\n",
        "  for doc in dict[word]:\n",
        "        # もし辞書オブジェクトに文書がないなら追加\n",
        "    if doc not in docs:\n",
        "      docs[doc] = 1\n",
        "\n",
        "# 総文書数（N）を求める\n",
        "docs_size = len(docs)\n",
        "\n",
        "### B. 文書頻度の算出\n",
        "\n",
        "# 索引語を一つずつ処理\n",
        "for key in dict:\n",
        "    # 文書数を取得し、dfに代入\n",
        "  df[key] = len(dict[key])\n",
        "\n",
        "### C. 逆文書頻度の算出\n",
        "\n",
        "# dfのキー（索引語）を一つずつ処理\n",
        "for word in df:\n",
        "    # idf値を計算し、格納\n",
        "  idf[word] = math.log( ( docs_size / df[word] ) + 1 )\n",
        "\n",
        "#---------------------------------------------\n",
        "# 5. 索引ファイルの書き出し\n",
        "#---------------------------------------------\n",
        "\n",
        "# ファイルを書き込みモードで開く\n",
        "f2 = open(index_file, 'w')\n",
        "\n",
        "# ソートした索引語を一つずつ処理\n",
        "for word in sorted(dict):\n",
        "    # ソートした文書を一つずつ処理\n",
        "  for doc in sorted(dict[word]):\n",
        "        ### A. tfidf値の算出\n",
        "    tfidf = dict[word][doc] * idf[word]\n",
        "        ### B. 索引語と重みデータの出力\n",
        "    f2.write(word + '\\t' + doc + '\\t' + str(dict[word][doc]) + '\\t' + str(idf[word]) + '\\t' + str(tfidf) +'\\n')\n",
        "\n",
        "# ファイルを閉じる\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jV8D2HtciYl"
      },
      "source": [
        "---\n",
        "### 課題1-2：索引付けプログラムの説明文を書きなさい\n",
        "\n",
        "- 課題1-1のプログラムを詳細に説明したものです。\n",
        "\n",
        "> 7:パソコンにあるファイルにアクセスするためのosライブラリを読み込む\n",
        "\n",
        "> 8:logメソッドを用いるためにmathライブラリを読み込む。\n",
        "\n",
        "> 9:正規表現を扱うためにreライブラリを読み込む。\n",
        "\n",
        "> 10:janomeライブラリの中のTokenizerクラスを呼ぶ\n",
        "\n",
        "> 13:Tokenizerを初期化し、変数tに格納する\n",
        "\n",
        "> 18:変数DATAとしてデータファイルを指定する。\n",
        "\n",
        "> 20:変数INDEXとしてデータファイルを指定する。\n",
        "\n",
        "> 21:index_fileでindex3.txtを参照する。\n",
        "\n",
        "> 26:辞書オブジェクトdictを初期化する\n",
        "\n",
        "> 28:不要語辞書stopwordsを初期化する。\n",
        "\n",
        "> 30:ファイル名保存用辞書オブジェクトとしてdocsを作成する。\n",
        "\n",
        "> 32:df用辞書オブジェクトを初期化する。\n",
        "\n",
        "> 34:idf値用辞書オブジェクトを初期化する\n",
        "\n",
        "> 41:不要語としてマッチしたい文字列を、一文字だけのひらがな、カタカナ、句読点として指定する。\n",
        "\n",
        "> 44:不要語辞書に　という　を追加する。\n",
        "\n",
        "> 45:不要語辞書に　にて　を追加する。\n",
        "\n",
        "> 52:osのlistdirを用いてDATAの中のファイル名をループ文として呼び出す。\n",
        "\n",
        "> 54:filenameのファイルを読む用として開く\n",
        "\n",
        "> 56:読みだした文章をループで1行ずつ読み出す。\n",
        "\n",
        "> 58:tokenizeで行を形態素解析して、変数tokensに格納する。\n",
        "\n",
        "> 60:tokensについてループを行い、tokenとして一語ずつ読み出す\n",
        "\n",
        "> 61:surfaceで単語のみを抽出し、変数keyに保存する。\n",
        "\n",
        "> 64:keyが正規表現の不要語に当てはまるかチェックする。\n",
        "\n",
        "> 65:当てはまったら、このkeyの後ろの作業をスキップする。\n",
        "\n",
        "> 67:keyが不要語辞書の不要語に当てはまるかチェックする。\n",
        "\n",
        "> 68:当てはまったら、このkeyの後ろの作業をスキップする。\n",
        "\n",
        "> 70:if文を用いてdict内にkeyがあるか判定する。\n",
        "\n",
        "> 71:あった場合、if文を用いてそのキーの値が参照する無名辞書オブジェクトにファイル名をキーとするレコードが存在しているか判定する。\n",
        "\n",
        "> 72:存在していれば、単語とファイル名をキーとするレコードの値を1増やす。\n",
        "\n",
        "> 73:存在していない場合\n",
        "\n",
        "> 74:単語とファイル名をキーとして頻度1を値に挿入する。\n",
        "\n",
        "> 76:dict内にkeyがない場合\n",
        "\n",
        "> 77:そのキーを使ってdictに無名辞書オブジェクトを初期化し\n",
        "\n",
        "> 78:単語とファイル名をキーとして頻度1を値に挿入する。\n",
        "\n",
        "> 87:for文でdictのkeyをwordとして一つずつ処理する。\n",
        "\n",
        "> 89:for文でdictのwordの内部辞書オブジェクトをdocとしてひとつずつ処理する。\n",
        "\n",
        "> 91:もしdocs内にdocがないならば\n",
        "\n",
        "> 92:docをkeyとして値を1としてdocs内に格納する。\n",
        "\n",
        "> 95:docsのレコード数をlenを用いてdocs_sizeという変数に格納する。\n",
        "\n",
        "> 100:for文でdfのkeyをwordとして一つずつ処理する。\n",
        "\n",
        "> 102:文書数を取得してdfに代入する。\n",
        "\n",
        "> 107:dfの索引語についてループする。\n",
        "\n",
        "> 109:idf値をmathライブラリのlogを用いて、計算してidfのwordの値として格納する。\n",
        "\n",
        "> 116:index_fileのファイルを書く用として開く\n",
        "\n",
        "> 119:五十音順にソートしたdictについてwordを変数としてループを行う。\n",
        "\n",
        "> 121:dict[word]という無名辞書オブジェクトについてdocを変数としてループを行う。\n",
        "\n",
        "> 123:tfidf値を計算して変数tfidfに格納する。\n",
        "\n",
        "> 125:index3.txtに索引語、ファイル名、tf値、idf値、tfidf値を出力する。\n",
        "\n",
        "> 128:ファイルを閉じる。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9UBtEj_ciYm"
      },
      "source": [
        "---\n",
        "### 課題2-1：順位付け処理のプログラムを書きなさい\n",
        "\n",
        "- ノートブック5で作成したプログラムを清書したものです。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzeGl4xaciYm"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------------\n",
        "# 1. 初期設定\n",
        "#---------------------------------------------\n",
        "\n",
        "### A. ライブラリの読み込み\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "from janome.tokenizer import Tokenizer\n",
        "import re\n",
        "# 分かち書きクラスの初期化\n",
        "t = Tokenizer()\n",
        "\n",
        "### B. フォルダやファイル名の設定\n",
        "\n",
        "# 索引ファイルの指定\n",
        "INDEX = CJE3 + \"/index\"\n",
        "index_file = INDEX + \"/index3.txt\"\n",
        "\n",
        "### C. 各種辞書オブジェクトの初期化\n",
        "\n",
        "# 索引語idf値の辞書オブジェクト\n",
        "doc_idf = {}\n",
        "# 索引語tfidf値の辞書オブジェクト\n",
        "doc_tfidf={}\n",
        "# 検索語tf値の辞書オブジェクト\n",
        "query_tf={}\n",
        "# 検索語tfidf値の辞書オブジェクト\n",
        "query_tfidf={}\n",
        "# 不要語辞書オブジェクト\n",
        "stopwords = {}\n",
        "# 検索語の辞書オブジェクト\n",
        "query_words ={}\n",
        "# 順位付け対象文書用辞書オブジェクト\n",
        "ranking_docs = {}\n",
        "\n",
        "#---------------------------------------------\n",
        "# 2. 索引ファイルの読み込み\n",
        "#---------------------------------------------\n",
        "\n",
        "# 索引ファイルを読み込みモードで開く\n",
        "f1 = open(INDEX + '/index3.txt', 'r')\n",
        "\n",
        "# 索引ファイルを1行づつ処理\n",
        "for line in f1:\n",
        "\n",
        "    ### A. 行末処理と要素の分割\n",
        "    \n",
        "    # 行末の改行文字除去\n",
        "  line = line.rstrip()\n",
        "    # 行の分割\n",
        "  split_line = line.split(\"\\t\")\n",
        "    \n",
        "    # 配列要素の取得\n",
        "  word = split_line[0] \n",
        "  doc = split_line[1] \n",
        "  idf = float(split_line[2])\n",
        "  tfidf = float(split_line[3])\n",
        "    ### B. 重み値の取得\n",
        "  if word not in doc_idf:\n",
        "    doc_idf[word] = idf\n",
        "\n",
        "  if word in doc_tfidf:\n",
        "    doc_tfidf[word][doc] = tfidf\n",
        "  else:\n",
        "    doc_tfidf[word] = {}\n",
        "    doc_tfidf[word][doc] = tfidf\n",
        "\n",
        "### C. tfidf_scoresからデータフレームを作成\n",
        "tfidf_table = pd.DataFrame(doc_tfidf)\n",
        "\n",
        "# NaNを0に置き換える\n",
        "tfidf_table = tfidf_table.fillna(0)\n",
        "\n",
        "#---------------------------------------------\n",
        "# 3. 検索質問の処理\n",
        "#---------------------------------------------\n",
        "\n",
        "# 検索質問\n",
        "query = '吾輩は猫である'\n",
        "# 検索質問データフレーム用ファイル名\n",
        "query_file = 'query'\n",
        "\n",
        "### A. 不用語削除ルールの定義\n",
        "\n",
        "# 不要語としてマッチしたいパターンの定義\n",
        "pattern = re.compile(r\"^[　-ー]$\")\n",
        "# 不要語の追加\n",
        "stopwords['という'] = 1\n",
        "stopwords['にて'] = 1\n",
        "\n",
        "### B. 検索質問の分かち書き\n",
        "\n",
        "# 分かち書きされた語オブジェクトの処理\n",
        "tokens = t.tokenize(query)\n",
        "for token in tokens:\n",
        "  key = token.surface\n",
        "    ### C. 不用語処理\n",
        "  \n",
        "    # 正規表現\n",
        "  if pattern.match(key):\n",
        "    continue\n",
        "        \n",
        "    # 不用語リスト\n",
        "  if key in stopwords:\n",
        "    continue\n",
        "\n",
        "    #  検索語の追加とtf値の加算\n",
        "  if key in query_words:\n",
        "    query_words[key] += 1\n",
        "  else:\n",
        "    query_words[key] = 1\n",
        "\n",
        "### D. 検索語の重み付け\n",
        "\n",
        "# 索引語を一つずつ処理\n",
        "for index_word in doc_idf:\n",
        "    # 索引語をキーとした検索質問tf値用とtfidf値用オブジェクトを初期化\n",
        "  if index_word not in query_tf:\n",
        "    query_tf[index_word] = 0\n",
        "  if index_word not in query_tfidf:\n",
        "    query_tfidf[index_word] = {}\n",
        "    # キー：索引語、擬似文書名「query」、値：0\n",
        "  query_tfidf[index_word][query] = 0\n",
        "\n",
        "# 検索語を一つずつ処理\n",
        "for query_word in query_words:\n",
        "  for index_word in query_tf:\n",
        "    # 検索語==索引語なレコードのtf値をquery_wordsから代入\n",
        "    if query_word == index_word:\n",
        "      query_tf[index_word] += 1\n",
        "\n",
        "# 検索語の出現頻度（`tf`値）と`idf`値を使って、`tfidf`値を算出する\n",
        "for index_word in query_tf:\n",
        "  query_tfidf[index_word][query] = query_tf[index_word]*doc_idf[index_word]\n",
        "\n",
        "### D. query_tfidfからデータフレームを作成\n",
        "query_table = pd.DataFrame(query_tfidf)\n",
        "\n",
        "#---------------------------------------------\n",
        "# 4. 類似度の計算と順位付け\n",
        "#---------------------------------------------\n",
        "\n",
        "### A. 順位付け対象文書の同定\n",
        "for query_word in query_words:\n",
        "  for doc in doc_tfidf[query_word]:\n",
        "    if doc not in ranking_docs:\n",
        "      ranking_docs[doc] = 1\n",
        "\n",
        "# 対象文書を一つずつ処理\n",
        "for ranking_doc in ranking_docs:\n",
        "    ### B. 余弦関数の分子の算出\n",
        "    \n",
        "    # 分子変数の初期化\n",
        "  numerator = 0\n",
        "    # 文書データフレームからdocにマッチする行のデータを取得\n",
        "  doc_vec = tfidf_table.loc[ranking_doc]\n",
        "    # 検索質問データフレームからquery_fileにマッチする行のデータを取得\n",
        "  query_vec = query_table.loc[query]\n",
        "    # 検索質問ベクトルの要素を添字を使って巡回\n",
        "  for i in range(len(query_vec.values)):\n",
        "        # query_vecとdoc_vecのi番目の要素を掛け合わせて、分子変数に足していく\n",
        "    i_value = query_vec.values[i] * doc_vec.values[i]\n",
        "    numerator = numerator + i_value\n",
        "    ### C. 余弦関数の分母の算出\n",
        "    \n",
        "    # 分母変数の初期化\n",
        "  denominator = 0\n",
        "    # 検索語ベクトル積の変数の初期化\n",
        "  query_value = 0\n",
        "    # 索引語ベクトル積の変数の初期化\n",
        "  doc_value = 0\n",
        "    # 検索質問ベクトルの要素を添字を使って巡回\n",
        "  for i in range(len(query_vec.values)):\n",
        "        # 検索質問ベクトルのi番目の値の二乗をquery_valueに加算していく\n",
        "    query_value += query_vec.values[i]**2\n",
        "        # 文書ベクトルのi番目の値の二乗をdoc_valueに加算していく\n",
        "    doc_value += doc_vec.values[i]**2\n",
        "    \n",
        "    # query_valueとdoc_valueの平方根を掛け合わせて分母とする\n",
        "  denominator = math.sqrt(query_value) * math.sqrt(doc_value)\n",
        "    \n",
        "    ### D. 余弦関数の算出\n",
        "\n",
        "  cosine = numerator / denominator\n",
        "    # ranking_docsへ値を代入\n",
        "  ranking_docs[ranking_doc] = cosine\n",
        "\n",
        "#---------------------------------------------\n",
        "# 5. 順位付け結果の出力\n",
        "#---------------------------------------------\n",
        "\n",
        "# 類似度の高い順に文書を表示\n",
        "sorted(ranking_docs.items(), key=lambda x:x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nPSR1BRciYn"
      },
      "source": [
        "---\n",
        "### 課題2-2：順位付けプログラムの説明文を書きなさい\n",
        "\n",
        "- 課題2-1のプログラムを詳細に説明したものです。\n",
        "\n",
        "\n",
        "> 6: パソコンにあるファイルにアクセスするためのosライブラリを読み込む\n",
        "\n",
        "> 7: 平方根のメソッドを用いるためにmathライブラリを読み込む。\n",
        "\n",
        "> 8: pandasライブラリをpdとして読み込む\n",
        "\n",
        "> 9: janomeライブラリの中のTokenizerクラスを呼ぶ\n",
        "\n",
        "> 10: 正規表現を扱うためにreライブラリを読み込む。\n",
        "\n",
        "> 12: Tokenizerを初期化し、変数tに格納する\n",
        "\n",
        "> 17: 変数INDEXとしてデータファイルを指定する。\n",
        "\n",
        "> 18: :index_fileでindex3.txtを参照する。\n",
        "\n",
        "> 23: 索引語idf値の辞書オブジェクトを初期化する。\n",
        "\n",
        "> 25: 索引語tfidf値の辞書オブジェクトを初期化する。\n",
        "\n",
        "> 27: 検索語tf値の辞書オブジェクトを初期化する。\n",
        "\n",
        "> 29: 検索語tfidf値の辞書オブジェクトを初期化する。\n",
        "\n",
        "> 31: 不要語辞書オブジェクトを初期化する。\n",
        "\n",
        "> 33: 検索語の辞書オブジェクトを初期化する。\n",
        "\n",
        "> 35: 順位付け対象文書用辞書オブジェクトを初期化する。\n",
        "\n",
        "> 42: 索引ファイルを読み込みモードで開く\n",
        "\n",
        "> 45: 読みだした文章をループで1行ずつ読み出す。\n",
        "\n",
        "> 50: 行末の改行をrstrip()を用いて削除する。\n",
        "\n",
        "> 52: splitを用いて空白を境界として行を分割する。\n",
        "\n",
        "> 55: 分割した一つ目をwordという変数に保存する。\n",
        "\n",
        "> 56: 分割した二つ目をdocという変数に保存する。\n",
        "\n",
        "> 57: 分割した三つ目をidfという変数に保存する。\n",
        "\n",
        "> 58: 分割した四つ目をtfidfという変数に保存する。\n",
        "\n",
        "> 60: もしdoc_idfにwordがないならば\n",
        "\n",
        "> 61: wordをキー、idfを値として保存する。\n",
        "\n",
        "> 63: もしdoc_tfidfにwordがあるならば\n",
        "\n",
        "> 64: wordとファイル名をキー、tfidfを値として保存する。\n",
        "\n",
        "> 65: そうでなければ\n",
        "\n",
        "> 66: Wordをキーとする中に内部辞書オブジェクトを作成する。\n",
        "\n",
        "> 67: wordとファイル名をキー、tfidfを値として保存する。\n",
        "\n",
        "> 70: tfidf_scoresからデータフレームを作成\n",
        "\n",
        "> 73: NaNを0に置き換える\n",
        "\n",
        "> 80: 検索質問として'吾輩は猫である'を指定する。\n",
        "\n",
        "> 82: 検索質問データフレーム用ファイル名を初期化する。\n",
        "\n",
        "> 87: 不要語としてマッチしたい文字列を、一文字だけのひらがな、カタカナ、句読点として指定する。\n",
        "\n",
        "> 89: 不要語辞書に　という　を追加する。\n",
        "\n",
        "> 90: 不要語辞書に　にて　を追加する。\n",
        "\n",
        "> 95: Tokenizerを初期化し、変数tに格納する\n",
        "\n",
        "> 96: tokensについてループを行い、tokenとして一語ずつ読み出す\n",
        "\n",
        "> 97: surfaceで単語のみを抽出し、変数keyに保存する。\n",
        "\n",
        "> 101: :keyが正規表現の不要語に当てはまるかチェックする。\n",
        "\n",
        "> 102: 当てはまったら、このkeyの後ろの作業をスキップする。\n",
        "\n",
        "> 105: keyが不要語辞書の不要語に当てはまるかチェックする。\n",
        "\n",
        "> 106: 当てはまったら、このkeyの後ろの作業をスキップする。\n",
        "\n",
        "> 109: query_wordsの中にkeyがあるか条件分岐を行う。\n",
        "\n",
        "> 110: あったら、keyをキーとする値に+1をする。\n",
        "\n",
        "> 111: なかったら、\n",
        "\n",
        "> 112: keyをキー、値を1として作成する。\n",
        "\n",
        "> 117: 索引語を一つずつ処理\n",
        "\n",
        "> 119: もしquery_tfにindex_wordがなければ\n",
        "\n",
        "> 120: キーをindex_word、値を0として保存する。\n",
        "\n",
        "> 121: もしquery_tfidfにindex_wordがなければ\n",
        "\n",
        "> 122: キーをindex_wordとする内部辞書型オブジェクトを作成する。\n",
        "\n",
        "> 124: query_tfidfにキー二つ目をquery、値を0とするレコードを追加する。\n",
        "\n",
        "> 127: 検索語を一つずつ処理\n",
        "\n",
        "> 128: 索引語を一つずつ処理\n",
        "\n",
        "> 130：索引語と検索語が一致したならば\n",
        "\n",
        "> 131: query_tfのindex_wordをキーとする値を+1する。\n",
        "\n",
        "> 134: 検索語を一つずつ処理\n",
        "\n",
        "> 135: tfidf値を算出する。\n",
        "\n",
        "> 138: query_tfidfからデータフレームを作成\n",
        "\n",
        "> 145: リスト化した検索質問についてループ文で回す\n",
        "\n",
        "> 146: tfidf_scoresの二つ目のキーであるファイル名をループ文で回す\n",
        "\n",
        "> 147: if文で、もしranking_docsの中にファイル名をキーとした要素がなければ\n",
        "\n",
        "> 148: ファイル名をキー、値が1の要素をranking_docsに追加する。\n",
        "\n",
        "> 151: ranking_docsのキーのファイル名についてループ文で回す\n",
        "\n",
        "> 155: 分子の変数numeratorを初期化する\n",
        "\n",
        "> 157: 文書データフレームから行IDにマッチする行のデータを取得する。\n",
        "\n",
        "> 159: 検索質問データフレームからquery_fileにマッチする行のデータを取得\n",
        "\n",
        "> 161: ベクトルの次元の数だけ1から順にループ文で回す。\n",
        "\n",
        "> 163: 同じ次元の検索質問のtfidf値と指定ファイルのtfidf値をかけてi_valueに代入する。\n",
        "\n",
        "> 164:  i_valueをnumeratorに加算していく。\n",
        "\n",
        "> 168,170,172: 検索質問のtfidf値の二乗の和の平方根、指定ファイルのtfidf値の二乗の和の平方根、分母の変数をそれぞれ初期化する。\n",
        "\n",
        "> 174: ベクトルの次元の数だけ1から順にループ文で回す\n",
        "\n",
        "> 176: query_valueに検索質問の各次元のtfidf値の二乗を加算していく。\n",
        "\n",
        "> 178: doc_valueに指定ファイルの各次元のtfidf値の二乗を加算していく。\n",
        "\n",
        "> 181: 検索質問のtfidf値の二乗の和の平方根と指定ファイルのtfidf値の二乗の和の平方根をかけて分母に代入する。\n",
        "\n",
        "> 185: 分子を分母で割ってコサイン値を出す。\n",
        "\n",
        "> 187: ranking_docsのファイル名をキーとしたときの値をコサイン値にする。\n",
        "\n",
        "> 194: ranking_docsをソートして出力する。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHrrNbS8ciYn"
      },
      "source": [
        "---\n",
        "### 課題3-1（任意）：順位付け処理プログラムを高度化しなさい\n",
        "\n",
        "- 課題2-1で作成した順位付け処理プログラムを高度化しなさい。高度化する内容は自由に設定して良い。適宜[日本語マニュアル](https://docs.python.jp/3.6/index.html)やその他のリソースを参照しなさい。\n",
        "- 高度化の例\n",
        "  - （関数を用いた）プログラムのモジュール化\n",
        "  - インタラクティブシステム（ユーザの入力（検索質問）を受け取って、整形した検索結果を返す、など）\n",
        "  - 異なる順位付けアルゴリズムの実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xFcINV6ciYo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js2eaI0SciYo"
      },
      "source": [
        "---\n",
        "### 課題3-2（任意）：高度化プログラムの説明文を書きなさい\n",
        "\n",
        "- 課題3-1のプログラムを詳細に説明したものです。特に高度化した内容について丁寧に説明すること。\n",
        "\n",
        "> 1: ...\n",
        "\n",
        "> 2: ...\n",
        "\n",
        "> 3: ...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCSQko6fciYo"
      },
      "source": [
        "---\n",
        "### 課題4（任意）：後半5回の演習の感想を書いてください。\n",
        "\n",
        "回答例\n",
        "- 演習で初めて（あるいは改めて）学んだこと\n",
        "- 演習の優れていた点\n",
        "- 演習の改善点\n",
        "- その他の感想やメッセージ\n",
        "\n",
        "※課題4の内容は成績に影響しません。次年度演習の参考にさせていただきます。\n",
        "\n",
        "プログラムのか書き方や方針が丁寧で、実行例と照らし合わせることもできて、とても分かりやすかったです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZfoZW8aciYp"
      },
      "source": [
        "---\n",
        "Copyright &copy; 2021. Hideo Joho and Haitao Yu. All rights reserved.\n",
        "無断複製・転載・配布行為を禁止します。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}